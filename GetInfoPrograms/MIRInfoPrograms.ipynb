{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get MIRI programs info #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** Create a csv file with relevant information on all observed MIRI programs or a part and download data from MAST\n",
    "\n",
    "**Author:** Boris Trahin, Staff Scientist II, MIRI team\n",
    "\n",
    "**Last updated:** June 29, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Import useful packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroquery.mast.missions import MastMissions\n",
    "from astroquery.mast import Observations\n",
    "from astropy.table import unique, vstack, Table\n",
    "from datetime import date\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Get entire catalog of MIRI observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Either get all the data from MAST or directly read the csv file downloaded from MAST\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mast = False # False = get info directly from the csv file downloaded from MAST\n",
    "csv_file = './JWST_2024-08-06T08_53_31-04_00.csv' # csv file\n",
    "save = True # save the catalogs into csv file\n",
    "\n",
    "good_columns = ['obs_id', 'fileSetName', 'program', 'proposal_cycle', 'date_obs', 'visitgrp',\n",
    "       'observtn', 'bkgdtarg', 'visit',\n",
    "       'targtype', 'exp_type', 'tsovisit', 'expripar', 'detector',\n",
    "       'opticalElements', 'filter', 'subarray', 'pps_aper', 'apername',\n",
    "       'miri_channel', 'miri_band', 'miri_coronmsk', 'targ_ra', 'targ_dec',\n",
    "       'nresets', 'nframes', 'ngroups', 'nints', 'readpat', 'numdthpt',\n",
    "       'patttype', 'miri_dithopfr', 'miri_numdsets',\n",
    "       'tframe', 'tgroup', 'effinttm','duration', 'eng_qual',\n",
    "       'hga_move', 'lamp', 'pcs_mode', 'miri_cccstate', 'exp_only', 'visitsta', 'template',\n",
    "       'targdesc', 'scicat', 'targcat', 'targprop', 'targname', 'obslabel', 'title',\n",
    "       'pi_name', 'category', 'access']\n",
    "\n",
    "if mast:\n",
    "    missions = MastMissions(mission='jwst')\n",
    "    results = missions.query_criteria(select_cols=good_columns,\n",
    "    instrume='MIRI',\n",
    "    limit=-1        \n",
    "        )\n",
    "    df = results.to_pandas()\n",
    "    update = date.today()\n",
    "else:\n",
    "    df = pd.read_csv(csv_file, low_memory=False)\n",
    "    bad_columns = [x for x in df.columns if x not in good_columns]\n",
    "    df = df.drop(bad_columns, axis='columns')\n",
    "    update = csv_file.split('_')[1][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Some columns are badly reference (e.g. MRS detector), so organize it.\n",
    "One can uncomment the line df2 = df2.drop_duplicates(subset=['obs_id', 'exp_type']) to remove duplicates based on obs_id and exp_type. This will keep only 1 dither position per exposure.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.reindex(good_columns, axis=1)\n",
    "\n",
    "# Some columns are badly referenced\n",
    "df2['detector'] = df2['detector'].fillna('')\n",
    "df2['detector'] = df2['detector'].astype(str)\n",
    "df2.loc[(df2['opticalElements'].str.contains('CH12')) & (df2['opticalElements'].str.contains('CH34')) & (df2['detector'].str.contains('MIRIFU')), 'detector'] = 'MIRIFUSHORT, MIRIFULONG'\n",
    "df2.loc[(df2['opticalElements'].str.contains('CH12')) & (df2['opticalElements'].str.contains('CH34')) & (df2['opticalElements'].str.contains('F')) & (df2['detector'].str.contains('MIRIFU')), 'detector']  = 'MIRIFUSHORT, MIRIFULONG, MIRIMAGE'\n",
    "\n",
    "for index, row in df2.iterrows():\n",
    "    if ('CH12' in str(df2['opticalElements'][index])) & ('CH34' in str(df2['opticalElements'][index])) & ('F' in str(df2['opticalElements'][index])):\n",
    "        df2.loc[index,'filter'] = df2.loc[index,'opticalElements'].split(',')[-1].replace(',','-')\n",
    "        \n",
    "df2.loc[(df2['exp_type'].astype(str).str.contains('MIR_DARKMRS', na=False)), 'detector'] = 'MIRIFUSHORT, MIRIFULONG'\n",
    "\n",
    "df2['miri_channel'] = df2['miri_channel'].fillna('')\n",
    "df2['miri_channel'] = df2['miri_channel'].astype(str)\n",
    "df2.loc[(df2['opticalElements'].str.contains('CH12')) & (df2['opticalElements'].str.contains('CH34')) & (df2['detector'].str.contains('MIRIFU')), 'miri_channel'] = '12, 34'\n",
    "df2.loc[(df2['opticalElements'].str.contains('OPAQUE')) & (df2['detector'].str.contains('MIRIFU')), 'miri_channel'] = '12, 34'\n",
    "\n",
    "df2['readpat'] = df2['readpat'].astype(str)\n",
    "df2.loc[(df2['tgroup']<3) & (df2['nresets']==1), 'readpat'] = 'FASTR1'\n",
    "df2.loc[(df2['tgroup']<3) & (df2['nresets']==0), 'readpat'] = 'FAST'\n",
    "df2.loc[(df2['tgroup']>3) & (df2['nresets']==1), 'readpat'] = 'SLOWR1'\n",
    "df2.loc[(df2['tgroup']>3) & (df2['nresets']==0), 'readpat'] = 'SLOW'\n",
    "\n",
    "df2 = df2.drop(df2[df2['fileSetName'].str.contains('-')].index)\n",
    "\n",
    "df2 = df2.sort_values(['program', 'observtn'],axis=0, ascending=False) # latest program first\n",
    "\n",
    "# df2 = df2.drop_duplicates(subset=['obs_id', 'exp_type']) # Uncomment this line to remove duplicates based on obs_id and exp_type. This will keep only 1 dither position per exposure.\n",
    "\n",
    "if save:\n",
    "    with open(f'./JWST_MIRI_programs_info_{update}.csv', 'w') as outfile:\n",
    "        # outfile.write(f'{date.today()}')\n",
    "        # outfile.write(f'\\n')\n",
    "        df2.to_csv(outfile, index=False) # save to a csv file and remove first index column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Search in the full catalog and create a sub-catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Change conditions in df_sort to create a sub-catalog\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search with conditions\n",
    "# condition = (df2['exp_type'].str.contains('IMAGE')) & (df2['ngroups']>100) & (df2['subarray'].str.contains('64'))\n",
    "condition = (df2['detector'].str.contains('MIRIMAGE') & df2['subarray'].str.contains('FULL'))\n",
    "# condition = (df2['exp_type'].str.contains('DARK')) & (df2['ngroups']>40) & (df2['subarray']=='FULL')\n",
    "\n",
    "df_sort = df2[condition]\n",
    "\n",
    "if save:\n",
    "    outfile = f'./Sorted_Catalog_MIRI.csv'\n",
    "    df_sort.to_csv(outfile, index=False) # save to a csv file and remove first index column\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "# df_sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Download data from MAST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Download the data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "search_mast_data = False\n",
    "download_mast_data = False\n",
    "download_dir = '/Users/btrahin/Data/'\n",
    "\n",
    "obs_ids = ['jw02114004001_04101_00002']\n",
    "extension = 'RATEINTS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if search_mast_data:\n",
    "    files = []\n",
    "    for i in obs_ids:\n",
    "        print(f'{obs_ids.index(i)+1}/{len(obs_ids)}. Getting observation {i} products...')\n",
    "        pid = i[2:7]\n",
    "        visitid = i[7:10]\n",
    "        obs = Observations.query_criteria(\n",
    "            obs_collection = 'JWST',\n",
    "            instrument_name = ['MIRI*'],\n",
    "            obs_id = f'jw{pid}*{visitid}*',\n",
    "            )\n",
    "        t = Observations.get_product_list(obs)\n",
    "        mask = (t['productType'] =='SCIENCE') & (t['productSubGroupDescription'] == extension)\n",
    "        t = t[mask]\n",
    "        for x in range(len(t)):\n",
    "            if (i in t['obs_id'][x]) and ('mirifulong' in t['obs_id'][x]):\n",
    "                files.append(t[x])\n",
    "    allfiles = unique(vstack(files), keys='productFilename')\n",
    "    products = Observations.filter_products(allfiles, extension='fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if download_mast_data:\n",
    "    personal_token = ''\n",
    "    Observations.login(token=personal_token)\n",
    "    Observations.download_products(\n",
    "        products,\n",
    "        curl_flag=True, # if True, a curl script will be downloaded that can be used to download the data files at a later time. Then run sh *file* in terminal.\n",
    "        download_dir=download_dir\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
